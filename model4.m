function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 19-Jul-2024 11:37:45.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = Qx5 matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = Qx1 matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [3.9315;13.3846;25;480;40];
x1_step1.gain = [0.0838447865311735;0.105596620908131;0.0210526315789474;0.000595238095238095;0.000183334861123843];
x1_step1.ymin = -1;

% Layer 1
b1 = [0.51346240048374403031;-1.6227764287798873699;-1.6141537857079595319;-1.795730005417676578;0.79996167806874907136;0.028388275930149003967;-1.6900413494695398775;1.7388419193899642412;0.51436479104914856197;0.50857622855776318804];
IW1_1 = [0.71003666503844542479 -0.23835851648321093599 -3.1410163502538690494 0.27082454392737731474 -0.13245481871476713631;0.84838588709933182574 -0.66827763816835139554 0.8543070620378129254 -2.3808020868032278017 1.5393285563047545139;0.46891405462802970838 0.022473917083199623779 1.6973236279677454963 -0.032380950615748409216 0.37256069950139203417;0.18257446268411714474 1.3705764441249181917 -2.5581588577820069119 -0.31915004027278959242 -1.8614257847049373584;3.0880676054446918322 1.8155022416983095379 -0.19680477110285674036 -0.02041955934552840829 -0.89501104417689592019;-3.1236079920455326331 -2.3113134239203780851 -1.9753307726588549276 -0.51449206315814932644 -0.17135609904003740178;-1.9765992895235757754 -0.1491310074504055283 0.2702345991593329555 0.055249367823007801415 -0.71232427283876720292;1.5649073278333025527 1.9169178773211468236 0.099521141186475536866 1.4427260450285197546 0.10499515190250202634;0.56097079812650085806 0.87915862461433347264 -0.19128164384128104603 -0.16515967964078751007 -0.62737912412303176168;-2.0121131284727495903 0.26282013938037651624 0.40463728540614141149 -1.1485449056294159131 1.3830932342068877894];

% Layer 2
b2 = 1.1147280890234412265;
LW2_1 = [0.35367194094299536644 0.097711648882627899493 0.81330816328660071601 0.10066060311302438279 0.72614861937379082679 -0.0704289404936424418 0.61516828085878805243 -0.14522470294034470206 -1.0080531337722620222 0.083965039170510860633];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = 0.104014978156855;
y1_step1.xoffset = 0.05;

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},1); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS

    % Input 1
    X{1,ts} = X{1,ts}';
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);

    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);

    % Layer 2
    a2 = repmat(b2,1,Q) + LW2_1*a1;

    % Output 1
    Y{1,ts} = mapminmax_reverse(a2,y1_step1);
    Y{1,ts} = Y{1,ts}';
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
x = bsxfun(@minus,y,settings.ymin);
x = bsxfun(@rdivide,x,settings.gain);
x = bsxfun(@plus,x,settings.xoffset);
end
